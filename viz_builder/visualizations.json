{
  "b0739a1a-ca0a-41fa-9adb-dc05f84d6b85": {
    "id": "b0739a1a-ca0a-41fa-9adb-dc05f84d6b85",
    "created_at": "2025-04-07T19:05:22.433085",
    "updated_at": "2025-04-09T16:12:54.572040",
    "code": "import streamlit as st\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nimport scipy\nimport math\nimport random\nimport datetime\nimport time\nimport json\nimport re\nimport os\nimport sys\nimport io\nimport collections\nimport itertools\nimport sklearn\nimport statsmodels\nimport statsmodels.api as sm\nimport altair as alt\nimport pygame\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings('ignore')\n\nst.title(\"Image Compression with PCA\")\n\nst.write(\"This app demonstrates image compression using Principal Component Analysis (PCA). PCA reduces the dimensionality of the image data, allowing for smaller file sizes with some loss of detail.\")\n\n# Image Upload\nuploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n\nif uploaded_file is not None:\n    image = Image.open(uploaded_file)\n    st.image(image, caption=\"Original Image\", use_container_width=True)\n\n    # Convert image to numpy array\n    img_array = np.array(image)\n\n    # Convert to Grayscale\n    if len(img_array.shape) == 3:\n        img_gray = np.dot(img_array[...,:3], [0.2989, 0.5870, 0.1140])\n    else:\n        img_gray = img_array\n\n    img_gray = img_gray.astype(np.uint8)\n\n    st.image(img_gray, caption=\"Grayscale Image\", use_container_width=True)\n    st.write(f\"Grayscale Image Shape: {img_gray.shape}\")\n\n    # Display the matrix of grayscale values\n    st.write(\"Grayscale Value Matrix:\")\n    st.dataframe(pd.DataFrame(img_gray))\n\n    # Number of components\n    n_components = st.slider(\"Number of Principal Components\", 1, img_gray.shape[1], img_gray.shape[1]//10)\n\n    # Reshape image into a matrix where each row is a pixel\n    img_matrix = img_gray\n\n    # Standardize the data\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(img_matrix)\n\n    # Apply PCA\n    pca = PCA(n_components=n_components)\n    pca.fit(scaled_data)\n    transformed_data = pca.transform(scaled_data)\n\n    # Inverse transform\n    inverse_data = pca.inverse_transform(transformed_data)\n\n    # Scale back to original range\n    inverse_data = scaler.inverse_transform(inverse_data)\n\n    # Clip values to be within the valid range\n    compressed_img = np.clip(inverse_data, 0, 255).astype(np.uint8)\n\n    # Display compressed image\n    st.image(compressed_img, caption=f\"Compressed Image with {n_components} Components\", use_container_width=True)\n\n    # Explained variance ratio\n    explained_variance = pca.explained_variance_ratio_\n    explained_variance_cumulative = np.cumsum(explained_variance)\n\n    # Plot explained variance\n    fig, ax = plt.subplots()\n    ax.plot(explained_variance_cumulative)\n    ax.set_xlabel(\"Number of Components\")\n    ax.set_ylabel(\"Cumulative Explained Variance\")\n    ax.set_title(\"Explained Variance vs. Number of Components\")\n    st.pyplot(fig)\n\n    # Display explained variance ratio data\n    variance_df = pd.DataFrame({'Component': range(1, len(explained_variance) + 1),\n                                  'Explained Variance': explained_variance,\n                                  'Cumulative Explained Variance': explained_variance_cumulative})\n    st.dataframe(variance_df)\n\n    # Compression Ratio\n    # The error was caused by trying to get the size of the uploaded file object directly.\n    # We need to save the file to a temporary location and then get the size.\n    temp_file = \"temp_image.jpg\"  # Or .png, depending on original\n    image.save(temp_file)\n    original_size = os.path.getsize(temp_file)\n    compressed_size = compressed_img.nbytes\n    compression_ratio = original_size / compressed_size\n    os.remove(temp_file)\n\n\n    st.write(f\"Original File Size: {original_size} bytes\")\n    st.write(f\"Compressed Image Size: {compressed_size} bytes\")\n    st.write(f\"Compression Ratio: {compression_ratio:.2f}\")\n\n    if st.button(\"Rerun\"):\n        st.rerun()\nelse:\n    st.write(\"Please upload an image to begin.\")",
    "title": "Image Compression with PCA using Streamlit",
    "description": "",
    "tags": [],
    "used_csv": null
  },
  "232d5513-d92f-42f1-a828-0a5f72a245b4": {
    "id": "232d5513-d92f-42f1-a828-0a5f72a245b4",
    "created_at": "2025-04-09T16:06:48.178903",
    "updated_at": "2025-04-09T16:06:48.178903",
    "code": "import streamlit as st\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nimport scipy\nimport math\nimport random\nimport datetime\nimport time\nimport json\nimport re\nimport os\nimport sys\nimport io\nimport collections\nimport itertools\nimport sklearn\nimport statsmodels\nimport statsmodels.api as sm\nimport altair as alt\nimport pygame\n\nst.title(\"Iris Dataset PCA Visualization\")\n\n# Load the Iris dataset\ntry:\n    iris_data = pd.read_csv('./upload/iris.csv')\nexcept FileNotFoundError:\n    st.error(\"The file 'iris.csv' was not found in the './upload/' directory.  Please upload the file or check the path.\")\n    st.stop()  # Stop execution if file is not found\n\nst.write(\"First 5 rows of the dataset:\")\nst.dataframe(iris_data.head())\n\n# Data Preprocessing\nfeatures = ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\nX = iris_data[features]\ny = iris_data['Species']\n\n# Standardize the features\nfrom sklearn.preprocessing import StandardScaler\nX = StandardScaler().fit_transform(X)\n\n# PCA implementation\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(X)\nprincipalDf = pd.DataFrame(data = principalComponents, columns = ['PCA1', 'PCA2'])\n\n# Concatenate with species information\nfinalDf = pd.concat([principalDf, iris_data[['Species']]], axis = 1)\n\nst.subheader(\"Explained Variance Ratio\")\nst.write(pca.explained_variance_ratio_)\n\n# Scatter Plot using Plotly Express\nfig = px.scatter(finalDf, x='PCA1', y='PCA2', color='Species',\n                 title='PCA of Iris Dataset',\n                 labels={'PCA1': 'Principal Component 1', 'PCA2': 'Principal Component 2'})\n\nst.plotly_chart(fig, use_container_width=True)",
    "title": "Iris Dataset: PCA Scatter Plot",
    "description": "",
    "tags": [],
    "used_csv": "iris.csv"
  },
  "cd92d301-0c25-4c26-b2f5-3f3a255d1919": {
    "id": "cd92d301-0c25-4c26-b2f5-3f3a255d1919",
    "created_at": "2025-04-09T19:47:41.655440",
    "updated_at": "2025-04-09T19:50:07.148126",
    "code": "import streamlit as st\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nimport scipy\nimport math\nimport random\nimport datetime\nimport time\nimport json\nimport re\nimport os\nimport sys\nimport io\nimport collections\nimport itertools\nimport sklearn\nimport statsmodels\nimport statsmodels.api as sm\nimport altair as alt\nimport pygame\n\n#st.set_option('deprecation.showPyplotGlobalUse', False)\n\nst.title(\"Image Convolution App\")\n\nuploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n\nif uploaded_file is not None:\n    # Load the image\n    try:\n        image = plt.imread(uploaded_file)\n    except Exception as e:\n        st.error(f\"Error loading image: {e}\")\n        st.stop()\n\n    st.subheader(\"Original Image\")\n    st.image(image, caption=\"Uploaded Image\", use_container_width=True)\n\n    # Convert to grayscale\n    gray_image = np.dot(image[...,:3], [0.2989, 0.5870, 0.1140]).astype(np.uint8)\n    st.subheader(\"Grayscale Image\")\n    st.image(gray_image, caption=\"Grayscale Image\", use_container_width=True)\n\n    # Define common kernels\n    kernels = {\n        \"Identity\": np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]]),\n        \"Sharpen\": np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n        \"Edge Detection\": np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]),\n        \"Box Blur\": (1/9) * np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]),\n        \"Gaussian Blur\": (1/16) * np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]])\n    }\n\n    kernel_names = list(kernels.keys())\n\n    # Kernel selection\n    selected_kernel_name = st.selectbox(\"Select a Predefined Kernel\", kernel_names)\n\n    # Manual kernel input\n    st.subheader(\"Or Input Custom Kernel (3x3)\")\n    col1, col2, col3 = st.columns(3)\n    k11 = col1.number_input(\"k11\", value=0.0, format=\"%.2f\")\n    k12 = col2.number_input(\"k12\", value=0.0, format=\"%.2f\")\n    k13 = col3.number_input(\"k13\", value=0.0, format=\"%.2f\")\n    \n    col4, col5, col6 = st.columns(3)\n    k21 = col4.number_input(\"k21\", value=0.0, format=\"%.2f\")\n    k22 = col5.number_input(\"k22\", value=0.0, format=\"%.2f\")\n    k23 = col6.number_input(\"k23\", value=0.0, format=\"%.2f\")\n\n    col7, col8, col9 = st.columns(3)\n    k31 = col7.number_input(\"k31\", value=0.0, format=\"%.2f\")\n    k32 = col8.number_input(\"k32\", value=0.0, format=\"%.2f\")\n    k33 = col9.number_input(\"k33\", value=0.0, format=\"%.2f\")\n\n    custom_kernel = np.array([[k11, k12, k13], [k21, k22, k23], [k31, k32, k33]])\n\n    use_custom_kernel = st.checkbox(\"Use custom kernel?\")\n\n    if use_custom_kernel:\n        selected_kernel = custom_kernel\n        selected_kernel_name = \"Custom Kernel\"\n    else:\n        selected_kernel = kernels[selected_kernel_name]\n    \n    st.write(f\"Selected Kernel: {selected_kernel_name}\")\n    st.write(selected_kernel)\n\n\n    # Convolution operation (simplified for demonstration)\n    def convolve(image, kernel):\n        kernel_size = kernel.shape[0]\n        padding = kernel_size // 2\n        padded_image = np.pad(image, padding, mode='constant')\n        output_image = np.zeros_like(image, dtype=np.float64)\n\n        for x in range(image.shape[0]):\n            for y in range(image.shape[1]):\n                output_image[x, y] = np.sum(padded_image[x:x+kernel_size, y:y+kernel_size] * kernel)\n        \n        output_image = np.clip(output_image, 0, 255).astype(np.uint8)\n\n        return output_image\n\n    # Apply convolution\n    convolved_image = convolve(gray_image, selected_kernel)\n\n    # Display convolved image\n    st.subheader(\"Convolved Image\")\n    st.image(convolved_image, caption=f\"Convolved Image with {selected_kernel_name}\", use_container_width=True)",
    "title": "Image Convolution Explorer",
    "description": "",
    "tags": [],
    "used_csv": null
  }
}